{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 100. Loss: 0.46369311213493347. Accuracy: 80.51\n",
      "Iteration: 200. Loss: 0.4890281558036804. Accuracy: 81.89\n",
      "Iteration: 300. Loss: 0.49713799357414246. Accuracy: 85.18\n",
      "Iteration: 400. Loss: 0.5358873605728149. Accuracy: 84.63\n",
      "Iteration: 500. Loss: 0.44168487191200256. Accuracy: 86.25\n",
      "Iteration: 600. Loss: 0.3038049638271332. Accuracy: 86.61\n",
      "Iteration: 700. Loss: 0.26195546984672546. Accuracy: 87.29\n",
      "Iteration: 800. Loss: 0.21691088378429413. Accuracy: 87.15\n",
      "Iteration: 900. Loss: 0.49018216133117676. Accuracy: 87.09\n",
      "Iteration: 1000. Loss: 0.27443867921829224. Accuracy: 87.77\n",
      "Iteration: 1100. Loss: 0.284212589263916. Accuracy: 87.55\n",
      "Iteration: 1200. Loss: 0.35525181889533997. Accuracy: 87.04\n",
      "Iteration: 1300. Loss: 0.29659757018089294. Accuracy: 88.35\n",
      "Iteration: 1400. Loss: 0.26283472776412964. Accuracy: 87.55\n",
      "Iteration: 1500. Loss: 0.399793803691864. Accuracy: 88.58\n",
      "Iteration: 1600. Loss: 0.2412887066602707. Accuracy: 88.32\n",
      "Iteration: 1700. Loss: 0.16593511402606964. Accuracy: 88.48\n",
      "Iteration: 1800. Loss: 0.1754751205444336. Accuracy: 88.74\n",
      "Iteration: 1900. Loss: 0.3629639148712158. Accuracy: 88.95\n",
      "Iteration: 2000. Loss: 0.2302512526512146. Accuracy: 88.75\n",
      "Iteration: 2100. Loss: 0.16280227899551392. Accuracy: 89.56\n",
      "Iteration: 2200. Loss: 0.29546836018562317. Accuracy: 88.87\n",
      "Iteration: 2300. Loss: 0.3106611669063568. Accuracy: 88.1\n",
      "Iteration: 2400. Loss: 0.2856740653514862. Accuracy: 89.13\n",
      "Iteration: 2500. Loss: 0.29050856828689575. Accuracy: 89.43\n",
      "Iteration: 2600. Loss: 0.1264059990644455. Accuracy: 89.41\n",
      "Iteration: 2700. Loss: 0.2894025444984436. Accuracy: 89.11\n",
      "Iteration: 2800. Loss: 0.2184361070394516. Accuracy: 89.6\n",
      "Iteration: 2900. Loss: 0.26199883222579956. Accuracy: 89.66\n",
      "Iteration: 3000. Loss: 0.2513772249221802. Accuracy: 89.6\n",
      "Iteration: 3100. Loss: 0.3985079824924469. Accuracy: 89.47\n",
      "Iteration: 3200. Loss: 0.25690460205078125. Accuracy: 89.61\n",
      "Iteration: 3300. Loss: 0.25543537735939026. Accuracy: 89.64\n",
      "Iteration: 3400. Loss: 0.23348812758922577. Accuracy: 89.47\n",
      "Iteration: 3500. Loss: 0.17600442469120026. Accuracy: 89.79\n",
      "Iteration: 3600. Loss: 0.28559112548828125. Accuracy: 89.83\n",
      "Iteration: 3700. Loss: 0.1631724238395691. Accuracy: 89.48\n",
      "Iteration: 3800. Loss: 0.1671040654182434. Accuracy: 89.56\n",
      "Iteration: 3900. Loss: 0.24517694115638733. Accuracy: 89.57\n",
      "Iteration: 4000. Loss: 0.2797800898551941. Accuracy: 90.27\n",
      "Iteration: 4100. Loss: 0.20187920331954956. Accuracy: 90.22\n",
      "Iteration: 4200. Loss: 0.23281817138195038. Accuracy: 89.59\n",
      "Iteration: 4300. Loss: 0.18821707367897034. Accuracy: 89.62\n",
      "Iteration: 4400. Loss: 0.12657715380191803. Accuracy: 89.82\n",
      "Iteration: 4500. Loss: 0.1407240927219391. Accuracy: 90.0\n",
      "Iteration: 4600. Loss: 0.18983995914459229. Accuracy: 90.14\n",
      "Iteration: 4700. Loss: 0.22919654846191406. Accuracy: 90.01\n",
      "Iteration: 4800. Loss: 0.259835422039032. Accuracy: 90.21\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch.utils.data as data\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import errno\n",
    "import torch\n",
    "import codecs\n",
    "\n",
    "\n",
    "class fashion(data.Dataset):\n",
    "    \"\"\"`MNIST <http://yann.lecun.com/exdb/mnist/>`_ Dataset.\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where ``processed/training.pt``\n",
    "            and  ``processed/test.pt`` exist.\n",
    "        train (bool, optional): If True, creates dataset from ``training.pt``,\n",
    "            otherwise from ``test.pt``.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "    \"\"\"\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "    raw_folder = 'raw'\n",
    "    processed_folder = 'processed'\n",
    "    training_file = 'training.pt'\n",
    "    test_file = 'test.pt'\n",
    "\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=True):\n",
    "        self.root = os.path.expanduser(root)\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.train = train \n",
    "\n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_exists():\n",
    "            raise RuntimeError('Download=True set')\n",
    "\n",
    "        if self.train:\n",
    "            self.train_data, self.train_labels = torch.load(\n",
    "                os.path.join(root, self.processed_folder, self.training_file))\n",
    "        else:\n",
    "            self.test_data, self.test_labels = torch.load(os.path.join(root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        if self.train:\n",
    "            img, target = self.train_data[index], self.train_labels[index]\n",
    "        else:\n",
    "            img, target = self.test_data[index], self.test_labels[index]\n",
    "\n",
    "        img = Image.fromarray(img.numpy(), mode='L')\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.test_data)\n",
    "\n",
    "    def _check_exists(self):\n",
    "        return os.path.exists(os.path.join(self.root, self.processed_folder, self.training_file)) and \\\n",
    "            os.path.exists(os.path.join(self.root, self.processed_folder, self.test_file))\n",
    "\n",
    "    def download(self):\n",
    "\n",
    "        from six.moves import urllib\n",
    "        import gzip\n",
    "\n",
    "        if self._check_exists():\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            os.makedirs(os.path.join(self.root, self.raw_folder))\n",
    "            os.makedirs(os.path.join(self.root, self.processed_folder))\n",
    "        except OSError as e:\n",
    "            if e.errno == errno.EEXIST:\n",
    "                pass\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        for url in self.urls:\n",
    "            print('Downloading ' + url)\n",
    "            data = urllib.request.urlopen(url)\n",
    "            filename = url.rpartition('/')[2]\n",
    "            file_path = os.path.join(self.root, self.raw_folder, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(data.read())\n",
    "            with open(file_path.replace('.gz', ''), 'wb') as out_f, \\\n",
    "                    gzip.GzipFile(file_path) as zip_f:\n",
    "                out_f.write(zip_f.read())\n",
    "            os.unlink(file_path)\n",
    "\n",
    "\n",
    "        print('Processing...')\n",
    "\n",
    "        training_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 'train-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 'train-labels-idx1-ubyte'))\n",
    "        )\n",
    "        test_set = (\n",
    "            read_image_file(os.path.join(self.root, self.raw_folder, 't10k-images-idx3-ubyte')),\n",
    "            read_label_file(os.path.join(self.root, self.raw_folder, 't10k-labels-idx1-ubyte'))\n",
    "        )\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.training_file), 'wb') as f:\n",
    "            torch.save(training_set, f)\n",
    "        with open(os.path.join(self.root, self.processed_folder, self.test_file), 'wb') as f:\n",
    "            torch.save(test_set, f)\n",
    "\n",
    "        print('Done!')\n",
    "\n",
    "\n",
    "def get_int(b):\n",
    "    return int(codecs.encode(b, 'hex'), 16)\n",
    "\n",
    "\n",
    "def parse_byte(b):\n",
    "    if isinstance(b, str):\n",
    "        return ord(b)\n",
    "    return b\n",
    "\n",
    "\n",
    "def read_label_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2049\n",
    "        length = get_int(data[4:8])\n",
    "        labels = [parse_byte(b) for b in data[8:]]\n",
    "        assert len(labels) == length\n",
    "        return torch.LongTensor(labels)\n",
    "\n",
    "\n",
    "def read_image_file(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        data = f.read()\n",
    "        assert get_int(data[:4]) == 2051\n",
    "        length = get_int(data[4:8])\n",
    "        num_rows = get_int(data[8:12])\n",
    "        num_cols = get_int(data[12:16])\n",
    "        images = []\n",
    "        idx = 16\n",
    "        for l in range(length):\n",
    "            img = []\n",
    "            images.append(img)\n",
    "            for r in range(num_rows):\n",
    "                row = []\n",
    "                img.append(row)\n",
    "                for c in range(num_cols):\n",
    "                    row.append(parse_byte(data[idx]))\n",
    "                    idx += 1\n",
    "        assert len(images) == length\n",
    "        return torch.ByteTensor(images).view(-1, 28, 28)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "train_dataset = fashion(root='./data',\n",
    "                            train=True,\n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = fashion(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "batch_size = 100\n",
    "n_iters = 5000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        #MODEL:\n",
    "        ##Conv layers: Conv2D, relu activation, batch norm, max pooling\n",
    "        ##Fully Connected layer: linear layer\n",
    "\n",
    "        self.cnn1= nn.Conv2d(in_channels=1, out_channels= 16, kernel_size=5, stride=1, padding=2)\n",
    "\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.MaxPool1 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        self.cnn2 = nn.Conv2d(in_channels= 16, out_channels= 32, kernel_size=5,stride=1, padding=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.MaxPool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.cnn3 = nn.Conv2d(in_channels= 32, out_channels= 64, kernel_size=5,stride=1, padding=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.MaxPool3 = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(576, 10)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.cnn1(x)\n",
    "        out= self.relu1(out)\n",
    "        our = self.conv1_bn(out)\n",
    "        \n",
    "        out= self.MaxPool1(out)\n",
    "        \n",
    "        out= self.cnn2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.conv2_bn(out)\n",
    "        \n",
    "        out = self.MaxPool2(out)\n",
    "        \n",
    "        out= self.cnn3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.conv3_bn(out)\n",
    "        \n",
    "        out = self.MaxPool3(out)\n",
    "        \n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = CNNModel()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "iter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        iter +=1\n",
    "        \n",
    "        if iter%100 ==0:\n",
    "            correct= 0\n",
    "            total=0\n",
    "            \n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                    \n",
    "                total += labels.size(0)\n",
    "                    \n",
    "                correct += (predicted==labels).sum()\n",
    "        \n",
    "            accuracy = 100*correct/total\n",
    "            \n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.data[0], accuracy))\n",
    "\n",
    "torch.save(model.state_dict(), 'cnn.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
